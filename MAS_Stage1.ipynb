{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A project in Multi-agent Systems: Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our reward structure comprises the following. The agent gets\n",
    "\n",
    "- +5 points for reaching location A.\n",
    "- +20 points for reaching location B when carrying the item \n",
    "    (this is possible since we can track if the agent has picked up the item or not)\n",
    "- -1 point for each step taken.\n",
    "- 0 points for standing still.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, grid_size=5):\n",
    "        self.grid_size = grid_size\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.reward = 0\n",
    "        self.agent_position = (0,0) # testing\n",
    "        #self.agent_position = (np.random.randint(0, self.grid_size - 1), np.random.randint(0, self.grid_size - 1))\n",
    "        self.item_position = (1,0) # testing\n",
    "        #self.item_position = (np.random.randint(0, self.grid_size - 1), np.random.randint(0, self.grid_size - 1))\n",
    "        self.target_position = (2,0) # testing\n",
    "        #self.target_position = (np.random.randint(0, self.grid_size - 1), np.random.randint(0, self.grid_size - 1))\n",
    "\n",
    "        self.carrying_item = False\n",
    "        self.done = False\n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self):\n",
    "        return (self.agent_position, self.item_position, self.carrying_item, self.reward, self.done)\n",
    "\n",
    "    def step(self, action):\n",
    "        x, y = self.agent_position\n",
    "        # we represent x as the vertical position (rows). y is the horizontal position (columns).\n",
    "        # we wont let the agent move outside the grid\n",
    "        if action == 0: # north\n",
    "            pos = (max(x-1, 0), y)\n",
    "        elif action == 1: # south\n",
    "            pos = (min(x+1, self.grid_size - 1), y)\n",
    "        elif action == 2: # west\n",
    "            pos = (x, max(y-1, 0))\n",
    "        elif action == 3:\n",
    "            pos = (x, min(y+1, self.grid_size - 1))\n",
    "        else:\n",
    "            raise ValueError(\"The action was invalid. Choose a number between 0 to 3\")\n",
    "        \n",
    "        self.agent_position = pos\n",
    "\n",
    "        # took a step, so reward - 1\n",
    "        self.reward -=1\n",
    "\n",
    "        # Checking if we picked up the item        \n",
    "        if self.agent_position == self.item_position and not self.carrying_item:\n",
    "            print('gotitem')\n",
    "            self.reward += 5  # +5 points for reaching location A\n",
    "            self.carrying_item = True\n",
    "\n",
    "        # Checking if we're done\n",
    "        if self.agent_position == self.target_position and self.carrying_item:\n",
    "            self.reward += 20 # +10 points for reaching location B when carrying the item\n",
    "            print('gotthere')\n",
    "            self.done = True\n",
    "\n",
    "\n",
    "        return self._get_state(), self.reward, self.done\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gotitem\n",
      "reward: 4, done: False\n",
      "gotthere\n",
      "reward: 23, done: True\n"
     ]
    }
   ],
   "source": [
    "env = GridWorld(grid_size=5) \n",
    "state = env.reset()\n",
    "\n",
    "# test here. you can change parameters in the reset function for proper testing\n",
    "actions = [1, 1, 1, 1, 1, 1, 1] # see the step function for the mapping of the movements\n",
    "for action in actions:\n",
    "    state, reward, done = env.step(action)\n",
    "    print(f\"reward: {reward}, done: {done}\")\n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
